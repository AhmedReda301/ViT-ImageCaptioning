# <span style="color:#FFA500;"> ViT-ImageCaptioning</span>

A <span style="color:#00BFFF;">deep learning</span> project for automatically generating **descriptive captions** for images.  
It includes full <span style="color:#32CD32;">data preprocessing</span>, <span style="color:#32CD32;">model training</span>, and <span style="color:#32CD32;">evaluation</span> using **four model variants**:

  1. **ViT + Transformer**  
  2. **CNN + Transformer**  
  3. **CNN + LSTM**  
  4. **CNN + LSTM with Attention mechanism**  

> **Note:** Currently, only the **ViT + Transformer** model has been trained. The other variants have not been trained yet. The ViT model is still undergoing training and requires more time to reach optimal accuracy. Note that training this model is computationally intensive and can take up to three days.





